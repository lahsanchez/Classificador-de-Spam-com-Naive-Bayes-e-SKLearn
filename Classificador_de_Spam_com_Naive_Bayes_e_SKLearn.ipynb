{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classificador de Spam com Naive Bayes e SKLearn.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nrHQFVy0OcxN"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import BernoulliNB"
      ],
      "metadata": {
        "id": "aIidPsb3Og9H"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "NEWLINE = '\\n'\n",
        "SKIP_FILES = set(['cmds'])\n",
        "\n",
        "def read_files(path):\n",
        "    for root, dir_names, file_names in os.walk(path):\n",
        "        for path in dir_names:\n",
        "            read_files(os.path.join(root, path))\n",
        "    for file_name in file_names:\n",
        "        if file_name not in SKIP_FILES:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "        if os.path.isfile(file_path):\n",
        "            past_header, lines = False, []\n",
        "            #f = open(file_path)\n",
        "            f = open(file_path, mode=\"r\", encoding=\"Latin-1\")\n",
        "            for line in f:\n",
        "                if past_header:\n",
        "                    lines.append(line)\n",
        "                elif line == NEWLINE:\n",
        "                    past_header = True\n",
        "            f.close()\n",
        "            yield file_path, NEWLINE.join(lines)#.decode('cp1252', 'ignore')"
      ],
      "metadata": {
        "id": "H-mZKDyZOkVe"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "\n",
        "def build_data_frame(path, classification):\n",
        "  data_frame = DataFrame({'text': [], 'class': []})\n",
        "  for file_name, text in read_files(path):\n",
        "    data_frame = data_frame.append(\n",
        "        DataFrame({'text': [text], 'class': [classification]}, index=[file_name]))\n",
        "  return data_frame"
      ],
      "metadata": {
        "id": "fg1eFuFzOnkH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAM = 0\n",
        "SPAM = 1\n",
        "\n",
        "SOURCES = [\n",
        "      ('/content/drive/MyDrive/spamassassin/spam', SPAM),\n",
        "      ('/content/drive/MyDrive/spamassassin/hard_ham', HAM),\n",
        "      ('/content/drive/MyDrive/spamassassin/easy_ham', HAM)\n",
        "    ]\n",
        "\n",
        "data = DataFrame({'text': [], 'class': []})\n",
        "for path, classification in SOURCES:\n",
        "  data = data.append(build_data_frame(path, classification))\n",
        "  \n",
        "data = data.reindex(numpy.random.permutation(data.index))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "zczMwOYzOqD-",
        "outputId": "ee1b8a69-ef00-4880-9915-6aa47b92dbd9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-5ba10b8152d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSOURCES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuild_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-48d9048266ed>\u001b[0m in \u001b[0;36mbuild_data_frame\u001b[0;34m(path, classification)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbuild_data_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassification\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mdata_frame\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     data_frame = data_frame.append(\n\u001b[1;32m      7\u001b[0m         DataFrame({'text': [text], 'class': [classification]}, index=[file_name]))\n",
            "\u001b[0;32m<ipython-input-3-7a62ac737a0b>\u001b[0m in \u001b[0;36mread_files\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdir_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m             \u001b[0mread_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mSKIP_FILES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'file_names' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "count_vectorizer = CountVectorizer()\n",
        "counts = count_vectorizer.fit_transform(numpy.asarray(data['text']))"
      ],
      "metadata": {
        "id": "e66bsYR-Ou3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "classifier = MultinomialNB()\n",
        "targets = numpy.asarray(data['class'])\n",
        "classifier.fit(counts, targets)"
      ],
      "metadata": {
        "id": "K2DSlWXhOzZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "examples = ['Free Viagra call today!', \"I'm going to attend the Linux users group tomorrow.\"]\n",
        "example_counts = count_vectorizer.transform(examples)\n",
        "predictions = classifier.predict(example_counts)\n",
        "predictions # [1, 0]"
      ],
      "metadata": {
        "id": "CvKBN2TFO2ZV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "pipeline = Pipeline([\n",
        "  ('vectorizer',  CountVectorizer()),\n",
        "  ('classifier',  MultinomialNB()) ])\n",
        "\n",
        "pipeline.fit(numpy.asarray(data['text']), numpy.asarray(data['class']))\n",
        "pipeline.predict(examples) # [1, 0]"
      ],
      "metadata": {
        "id": "lLzcFnSPO5k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "  ('count_vectorizer',   CountVectorizer(ngram_range=(1, 2))),\n",
        "  ('classifier',         BernoulliNB(binarize=0.0)) ])"
      ],
      "metadata": {
        "id": "dHXwfjblO832"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "  ('count_vectorizer',   CountVectorizer(ngram_range=(1, 2))),\n",
        "  ('classifier',         BernoulliNB(binarize=0.0)) ])"
      ],
      "metadata": {
        "id": "g0gLSBKwO_eF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "Cc-7OmycPBws"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}